# 调用其他基础库
from transformers import AutoTokenizer, AutoModelForCausalLM
from typing import Dict, List, Optional, Tuple, Union
from warnings import warn
from copy import copy
import torch

# 调用 Lagent 及相关库
from lagent.llms.base_llm import BaseModel






class RoleplayerModel(BaseModel):
    """
    Roleplayer for InternLM2-Chat model

    Args:
        path (str): The path to the model.
        max_new_tokens (int): Maximum length of output expected to be generated by the model. Defaults
            to 512.
        tokenizer_only (bool): If True, only the tokenizer will be initialized.
            Defaults to False.
        meta_template (list of dict, optional): The model's meta prompt
            template if needed, in case the requirement of injecting or
            wrapping of any meta instructions.
    """

    def __init__(
            self,
            path: str,
            max_new_tokens: int = 512,
            top_p: float = 0.8,
            top_k: float = None,
            temperature: float = 0.8,
            repetition_penalty: float = 1.0,
            stop_words: Union[List[str], str] = None
    ):
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        self.model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, low_cpu_mem_usage=True, torch_dtype=torch.bfloat16).cuda()
        self.model = self.model.eval()
        
        # stop words
        if isinstance(stop_words, str):
            stop_words = [stop_words]
        self.gen_params = dict(
            max_new_tokens=max_new_tokens,
            top_p=top_p,
            top_k=top_k,
            temperature=temperature,
            repetition_penalty=repetition_penalty,
            stop_words=stop_words)

    def generate(
        self, 
        inputs: Union[str, List[str]], 
        **gen_params
    ) -> str:
        """
        Generate results given a str (or list of) inputs.

        Args:
            inputs (Union[str, List[str]]):
            gen_params (dict): The input params for generation.

        Returns:
            Union[str, List[str]]: A (list of) generated strings.
        """
        
        
        


